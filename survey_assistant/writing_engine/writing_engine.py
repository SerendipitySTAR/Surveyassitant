import jinja2
import logging
import os
import re # For tex_escape function
from datetime import datetime # Ensure datetime is imported
# import matplotlib.pyplot as plt # For actual plotting, if enabled
# import plotly.graph_objects as go # For actual interactive plotting, if enabled

logger = logging.getLogger(__name__)

import random # Added for theme visualization mock data

logger = logging.getLogger(__name__)

# Default Markdown template as a string
DEFAULT_MARKDOWN_TEMPLATE = """
# {{ report_data.overall_topic | default("Literature Survey") }}

## 1. Introduction
{{ report_data.introduction_text | default("Introduction placeholder.") }}

## 2. Key Themes and Insights
{% if report_data.themed_sections %}
{% for theme in report_data.themed_sections %}
### {{ loop.index }}. {{ theme.theme_name | default("Unnamed Theme") }}
**Summary:** {{ theme.theme_summary | default("No summary available for this theme.") }}
**Representative Keywords:** {{ theme.representative_keywords | join(", ") if theme.representative_keywords else "N/A" }}
**Papers Discussed:**
{% for paper_title in theme.paper_titles_in_theme %}
- {{ paper_title }} (ID: {{ theme.papers_in_theme[loop.index0] }})
{% else %}
- No specific papers listed for this theme.
{% endfor %}
{% if theme.visualization %}
**Visualization:**
![{{ theme.visualization.caption }}]({{ theme.visualization.path }})
*{{ theme.visualization.caption }}*
{% endif %}
{% endfor %}
{% else %}
No specific themes were identified or summarized.
{% endif %}

## 3. Methodologies Overview
**Common Methodologies Identified:**
{% if report_data.methodology_overview %}
<ul>
{% for method in report_data.methodology_overview %}
  <li>{{ method.method }} ({{ method.count }} paper(s))</li>
{% endfor %}
</ul>
{% else %}
No common methodologies were explicitly aggregated.
{% endif %}
{% if visualizations.methodology_chart %}
![Methodology Distribution]({{ visualizations.methodology_chart.path }})
*{{ visualizations.methodology_chart.caption }}*
{% endif %}

## 4. Reproducibility Assessment
**Summary:**
- Papers checked for reproducibility: {{ report_data.reproducibility_summary_data.total_papers_checked_for_reproducibility | default(0) }}
- Papers successfully reproduced (simulated): {{ report_data.reproducibility_summary_data.total_papers_reproduced_successfully | default(0) }}
{% if visualizations.reproducibility_chart %}
![Reproducibility Overview]({{ visualizations.reproducibility_chart.path }})
*{{ visualizations.reproducibility_chart.caption }}*
{% endif %}

**Details:**
{% if report_data.reproducibility_summary_data.details %}
<ul>
{% for detail in report_data.reproducibility_summary_data.details %}
  <li>Paper: {{ detail.title | default(detail.paper_id) }}
    <ul>
      <li>Checked: {{ "Yes" if detail.checked else "No" }}</li>
      {% if detail.checked %}
      <li>Reproduced: {{ "Yes" if detail.reproduced else "No" }} (Success Rate: {{ "%.2f"|format(detail.success_rate*100) if detail.success_rate is not none else 'N/A' }}%)</li>
      <li>Code URL: {{ detail.url if detail.url else "N/A" }}</li>
      {% endif %}
    </ul>
  </li>
{% endfor %}
</ul>
{% else %}
No detailed reproducibility information available.
{% endif %}

## 5. Conclusion
{{ report_data.conclusion_text | default("Conclusion placeholder.") }}

## Appendix: Detailed Evidence Packages
*(This section would typically list or link to individual evidence packages for deeper review. For brevity, it's omitted in this draft template.)*
{#
{% if report_data.source_evidence_packages %}
{% for pkg in report_data.source_evidence_packages %}
### Evidence for Paper: {{ pkg.title | default(pkg.paper_id) }}
**Summary:** {{ pkg.original_analysis_summary.summary | default("N/A") }}
**Contributions:** {{ pkg.original_analysis_summary.contributions | join("; ") if pkg.original_analysis_summary.contributions else "N/A" }}
**Limitations:** {{ pkg.original_analysis_summary.limitations | join("; ") if pkg.original_analysis_summary.limitations else "N/A" }}
**Claims Processed:** {{ pkg.processed_claims | length }}
---
{% endfor %}
{% endif %}
#}

## References
*(Placeholder: A full reference list would be generated based on papers included in `source_evidence_packages`)*
{% if report_data.source_evidence_packages %}
{% for pkg in report_data.source_evidence_packages %}
- {{ pkg.title | default(pkg.paper_id) }}. {{ pkg.source_url | default("") }}
{% endfor %}
{% endif %}

---
*Report generated by SurveyAssistant on {{ now() }}*
"""

DEFAULT_LATEX_TEMPLATE = r"""
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem} % For itemize indentation
\usepackage{array}   % For better table column definitions
\usepackage{booktabs} % For professional quality tables
\usepackage{longtable} % For tables that span multiple pages
\usepackage{geometry}
\geometry{a4paper, margin=1in}

\title{ {{- report_data.overall_topic | default("Literature Survey") -}} }
\author{SurveyAssistant}
\date{ {{- now() -}} }

\begin{document}
\maketitle
\begin{abstract}
    % Placeholder for abstract - could be generated by LLM or use intro
    This document provides a survey of literature concerning: {{ report_data.overall_topic | default("the specified research area") }}.
    It covers {{ report_data.statistics.total_papers_analyzed | default(0) }} analyzed papers, identifying
    {{ report_data.statistics.total_themes_identified | default(0) }} key themes.
\end{abstract}
\tableofcontents
\clearpage

\section{Introduction}
{{ report_data.introduction_text | default("Introduction placeholder.") | tex_escape }}

\section{Key Themes and Insights}
{% if report_data.themed_sections %}
{% for theme in report_data.themed_sections %}
\subsection{ {{ loop.index }}. {{ theme.theme_name | default("Unnamed Theme") | tex_escape }} }
\textbf{Summary:} {{ theme.theme_summary | default("No summary available for this theme.") | tex_escape }}

\textbf{Representative Keywords:} {% if theme.representative_keywords %}{{ theme.representative_keywords | map('tex_escape') | join(", ") }}{% else %}N/A{% endif %}

\textbf{Papers Discussed:}
\begin{itemize}[leftmargin=*]
{% for paper_title in theme.paper_titles_in_theme %}
    \item {{ paper_title | tex_escape }} (ID: {{ theme.papers_in_theme[loop.index0] | tex_escape }})
{% else %}
    \item No specific papers listed for this theme.
{% endfor %}
\end{itemize}
% Removing per-theme visualization block for LaTeX debugging
% {% if theme.visualization %}
%     % Visualization for theme: {{ theme.theme_name | tex_escape }}
%     % Caption: {{ theme.visualization.caption | tex_escape }}
%     \par\textit{Visualization for {{ theme.theme_name | tex_escape }}: {{ theme.visualization.caption | tex_escape }} (Content: {{ theme.visualization.text_content | first | truncate(50) }} / {{theme.visualization.latex_code | first | truncate(50) }}) } \par
% {% endif %}
{% endfor %}
{% else %}
No specific themes were identified or summarized.
{% endif %}

\section{Methodologies Overview}
\textbf{Common Methodologies Identified:}
{% if report_data.methodology_overview %}
\begin{itemize}[leftmargin=*]
{% for method in report_data.methodology_overview %}
  \item {{ method.method | tex_escape }} ({{ method.count }} paper(s))
{% endfor %}
\end{itemize}
{% else %}
No common methodologies were explicitly aggregated.
{% endif %}
{% if 'methodology_chart' in visualizations and visualizations.methodology_chart.get('latex_code') %}
% Visualization for methodologies
% Caption: {{ visualizations.methodology_chart.caption | tex_escape }}
\begin{figure}[h!]
    \centering
    \texttt{ {%- visualizations.methodology_chart.latex_code | default("Placeholder for methodology chart.") -%} }
    \caption{ {%- visualizations.methodology_chart.caption | tex_escape -%} }
    \label{fig:methodology_chart}
\end{figure}
{% elif 'methodology_chart' in visualizations %}
\begin{verbatim}
% Fallback for methodology_chart if latex_code is not present but chart object exists
{{ visualizations.methodology_chart.text_content | default("No textual visualization for methodologies.") }}
\end{verbatim}
\textit{Caption: {{ visualizations.methodology_chart.caption | tex_escape | default("Methodology Chart") }}}
{% endif %}
% ENDIF for methodology_chart visualization

\section{Reproducibility Assessment}
\subsection{Summary}
\begin{itemize}[leftmargin=*]
    \item Papers checked for reproducibility: {{ report_data.reproducibility_summary_data.total_papers_checked_for_reproducibility | default(0) }}
    \item Papers successfully reproduced (simulated): {{ report_data.reproducibility_summary_data.total_papers_reproduced_successfully | default(0) }}
\end{itemize}
% Temporarily removing reproducibility chart for debugging
% {% if 'reproducibility_chart' in visualizations and visualizations.reproducibility_chart.get('latex_code') %}
% % Visualization for reproducibility
% % Caption: {{ visualizations.reproducibility_chart.caption | tex_escape }}
% \begin{figure}[h!]
%     \centering
%     \texttt{ {%- visualizations.reproducibility_chart.latex_code | default("Placeholder for reproducibility chart.") -%} }
%     \caption{ {%- visualizations.reproducibility_chart.caption | tex_escape -%} }
%     \label{fig:repro_chart}
% \end{figure}
% {% elif 'reproducibility_chart' in visualizations %}
% \begin{verbatim}
% % Fallback for reproducibility_chart if latex_code is not present but chart object exists
% {{ visualizations.reproducibility_chart.text_content | default("No textual visualization for reproducibility.") }}
% \end{verbatim}
% \textit{Caption: {{ visualizations.reproducibility_chart.caption | tex_escape | default("Reproducibility Chart") }}}
% {% endif %}
% ENDIF for reproducibility_chart visualization

\subsection{Details}
{% if report_data.reproducibility_summary_data.details %}
\begin{itemize}[leftmargin=*]
{% for detail in report_data.reproducibility_summary_data.details %}
  \item Paper: {{ detail.title | default(detail.paper_id) | tex_escape }}
    \begin{itemize}[leftmargin=parindent]
      \item Checked: {{ "Yes" if detail.checked else "No" }}
      {% if detail.checked %}
      \item Reproduced: {{ "Yes" if detail.reproduced else "No" }} (Success Rate: {{ "%.2f"|format(detail.success_rate*100) if detail.success_rate is not none else 'N/A' }}\%)
      \item Code URL: \url{ {%- detail.url if detail.url else "N/A" -%} }
      {% endif %}
    \end{itemize}
{% endfor %}
\end{itemize}
{% else %}
No detailed reproducibility information available.
{% endif %}

\section{Conclusion}
{{ report_data.conclusion_text | default("Conclusion placeholder.") | tex_escape }}

% Appendix could be more detailed in a full version
\appendix
\section{Source Papers Overview}
A brief list of papers included in this survey:
\begin{itemize}[leftmargin=*]
{% if report_data.source_evidence_packages %}
{% for pkg in report_data.source_evidence_packages %}
    \item \textit{ {{- pkg.title | default(pkg.paper_id) | tex_escape -}} } (ID: {{ pkg.paper_id | tex_escape }}). Accessible at: \url{ {{- pkg.source_url | default("N/A") -}} }
{% endfor %}
{% else %}
    \item No source papers listed.
{% endif %}
\end{itemize}

\section{References}
% Basic bibliography - for a real paper, use BibTeX or similar.
\begin{thebibliography}{99}
{% if report_data.source_evidence_packages %}
{% for pkg in report_data.source_evidence_packages %}
    \bibitem{ {%- pkg.paper_id | replace(":", "_") | tex_escape -%} } {{- pkg.title | default(pkg.paper_id) | tex_escape -%}}.
    {% if pkg.source_url -%} Accessible at: \url{ {{- pkg.source_url -}} } {%- endif -%}
{% endfor %}
{% else %}
    \item No references available.
{% endif %}
\end{thebibliography}

\end{document}
"""

# LaTeX escaping filter for Jinja2
def tex_escape(text):
    """
    Escapes TeX special characters in a string for use in LaTeX.
    """
    if not isinstance(text, str):
        return text # Or convert to string: str(text)
    conv = {
        '&': r'\&',
        '%': r'\%',
        '$': r'\$',
        '#': r'\#',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '^': r'\^{}',
        '\\': r'\textbackslash{}',
        '<': r'\textless{}',
        '>': r'\textgreater{}',
    }
    regex = re.compile('|'.join(re.escape(str(key)) for key in sorted(conv.keys(), key = lambda item: - len(item))))
    return regex.sub(lambda match: conv[match.group()], text)


class WritingEngine:
    def __init__(self):
        """
        Initializes the WritingEngine.
        """
        try:
            # Setup Jinja2 environment
            # Using PackageLoader if templates were in a package, but here using DictLoader for string templates
            # Using an ultra-simplified LaTeX template for debugging the persistent Jinja2 error
            ULTRA_SIMPLE_LATEX_TEMPLATE_DEBUG = r"""
\documentclass{article}
\title{ {{- report_data.overall_topic | default("Test Title") | tex_escape -}} }
\author{Test Author}
\date{ {{- now() -}} }
\begin{document}
\maketitle
Hello, this is a test.
Introduction: {{ report_data.introduction_text | default("No intro") | tex_escape }}
\end{document}
"""
            self.jinja_env = jinja2.Environment(
                loader=jinja2.DictLoader({
                    "markdown": DEFAULT_MARKDOWN_TEMPLATE,
                    "latex": ULTRA_SIMPLE_LATEX_TEMPLATE_DEBUG # Using the ultra-simple one
                }),
                autoescape=jinja2.select_autoescape(['html', 'xml']), # MD and TeX don't need HTML autoescaping
                block_start_string='{%', block_end_string='%}',
                variable_start_string='{{', variable_end_string='}}',
                comment_start_string='{#', comment_end_string='#}',
                line_statement_prefix='%%', line_comment_prefix='%#', # For LaTeX-friendly comments if needed
                trim_blocks=True, lstrip_blocks=True # Good for template readability
            )
            self.jinja_env.globals['now'] = lambda: datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
            self.jinja_env.filters['tex_escape'] = tex_escape # Add custom filter

            logger.info("WritingEngine initialized with Jinja2 for Markdown and LaTeX.")
        except Exception as e:
            logger.error(f"Failed to initialize Jinja2 environment: {e}")
            self.jinja_env = None # Ensure it's None if init fails

    def _generate_text_visualization(self, data: list, title: str, value_key:str, label_key:str, viz_type:str="bar_chart", output_format="markdown") -> dict:
        """
        Generates a textual representation of a visualization (e.g., a simple bar chart).
        Actual image generation is complex for this environment and would be a separate microservice.
        """
        logger.info(f"Generating text visualization for '{title}' ({viz_type}).")

        # For this placeholder, we'll create a mock file path and a text description
        # In a real system, this might save an image and return its path, or save text data to a file.
        mock_output_dir = "output/visualizations" # ensure this exists or handle creation
        if not os.path.exists(mock_output_dir):
            try:
                os.makedirs(mock_output_dir)
            except OSError as e:
                logger.error(f"Could not create visualization directory {mock_output_dir}: {e}")
                # Fallback to no path if dir creation fails
                mock_output_dir = ""


        filename_safe_title = "".join(c if c.isalnum() else "_" for c in title)
        mock_file_path = os.path.join(mock_output_dir, f"{filename_safe_title}_{viz_type}.txt") if mock_output_dir else ""

        text_viz_content = [f"--- Text Visualization: {title} ({viz_type}) ---"]
        if not data:
            text_viz_content.append("No data available for this visualization.")
        elif viz_type == "bar_chart":
            max_val = max(item.get(value_key, 0) for item in data) if data else 0
            max_bar_len = 30 # Max characters for a bar
            for item in sorted(data, key=lambda x: x.get(value_key, 0), reverse=True):
                label = item.get(label_key, "N/A")
                value = item.get(value_key, 0)
                bar_len = int((value / max_val) * max_bar_len) if max_val > 0 else 0
                bar = "#" * bar_len
                text_viz_content.append(f"{label:<20} | {bar} ({value})")
        else: # Other types just list data
            for item in data:
                 text_viz_content.append(f"- {item.get(label_key, 'Item')}: {item.get(value_key, 'N/A')}")

        # In a real scenario, we might save this to mock_file_path
        # For now, the path is just a reference. The content can be embedded if desired or linked.
        # For simplicity, the current template doesn't embed this text viz, only links to the path.

        latex_code = ""
        if output_format == "latex":
            # Generate simple LaTeX table or text for visualization
            if viz_type == "bar_chart" and data:
                latex_code += "\\begin{itemize}[leftmargin=*]\n"
                for item in sorted(data, key=lambda x: x.get(value_key, 0), reverse=True):
                    label = tex_escape(str(item.get(label_key, "N/A")))
                    value = item.get(value_key, 0)
                    latex_code += f"    \\item {label}: {value}\n"
                latex_code += "\\end{itemize}\n"
            else:
                latex_code = f"Data for {tex_escape(title)}: " + ", ".join(f"{tex_escape(str(item.get(label_key,'')))}: {item.get(value_key,'')}" for item in data)

        return {
            "type": viz_type,
            "path": mock_file_path.replace("output/", "") if mock_file_path and output_format == "markdown" else "", # Relative path for Markdown
            "caption": f"Visualization of {title} ({viz_type}). Data stored at: {mock_file_path}",
            "text_content": "\n".join(text_viz_content), # The actual text viz
            "latex_code": latex_code # LaTeX specific code for the visualization
        }

    def compose(self, structured_report_data: dict, output_format: str = "markdown") -> str:
        """
        Composes the literature survey draft from structured data using a Jinja2 template.
        structured_report_data: Data from KnowledgeWeaver.
        output_format: "markdown" or "latex".
        Returns the composed draft as a string.
        """
        if not self.jinja_env:
            logger.error("Jinja2 environment not initialized. Cannot compose document.")
            return "Error: Document template environment not available."

        template_name = output_format
        try:
            template = self.jinja_env.get_template(template_name)
        except jinja2.TemplateNotFound:
            logger.error(f"Template '{template_name}' not found. Cannot compose document.")
            return f"Error: Template for format '{template_name}' not found."
        except Exception as e:
            logger.error(f"Error loading template '{template_name}': {e}")
            return f"Error loading template: {e}"


        logger.info(f"WritingEngine: Composing draft for topic '{structured_report_data.get('overall_topic', 'N/A')}' in {output_format} format.")

        visualizations = {}
        if structured_report_data.get("methodology_overview"):
            visualizations["methodology_chart"] = self._generate_text_visualization(
                data=structured_report_data["methodology_overview"],
                title="Methodology Distribution", value_key="count", label_key="method",
                viz_type="bar_chart", output_format=output_format
            )

        repro_summary = structured_report_data.get("reproducibility_summary_data", {})
        repro_data_for_chart = [
            {"status": "Checked & Reproduced", "count": repro_summary.get("total_papers_reproduced_successfully",0)},
            {"status": "Checked & Not Reproduced/Issues", "count": repro_summary.get("total_papers_checked_for_reproducibility",0) - repro_summary.get("total_papers_reproduced_successfully",0)},
        ]
        if repro_data_for_chart[0]['count'] > 0 or repro_data_for_chart[1]['count'] > 0 : # Only if there's data
             visualizations["reproducibility_chart"] = self._generate_text_visualization(
                data=repro_data_for_chart, title="Reproducibility Overview", value_key="count", label_key="status",
                viz_type="bar_chart", output_format=output_format
            )

        template_context = {
            "report_data": structured_report_data,
            "visualizations": visualizations
        }

        if "themed_sections" in template_context["report_data"]:
            for theme in template_context["report_data"]["themed_sections"]:
                if theme.get("has_quantitative_data"):
                    theme_viz_data = [{"label": f"Metric A for {theme['theme_name']}", "value": random.randint(10,100)},
                                      {"label": f"Metric B for {theme['theme_name']}", "value": random.randint(5,50)}]
                    theme["visualization"] = self._generate_text_visualization(
                        data=theme_viz_data, title=f"Key Metrics for {theme['theme_name']}",
                        value_key="value", label_key="label", viz_type="bar_chart", output_format=output_format
                    )
        try:
            rendered_draft = template.render(template_context)
            logger.info(f"WritingEngine: Draft composed successfully in {output_format} format.")
            return rendered_draft
        except Exception as e:
            logger.error(f"Error rendering Jinja2 template for {output_format}: {e}")
            return f"Error during document composition for {output_format}: {e}"

    def to_docx_simulation(self, markdown_content: str, output_md_filepath: str = "output/survey_draft_for_docx.md") -> dict:
        """
        Simulates DOCX generation by saving the Markdown content and providing instructions.
        Args:
            markdown_content: The Markdown string.
            output_md_filepath: Path to save the intermediate Markdown file.
        Returns:
            A dictionary with a message and the path to the saved Markdown file.
        """
        logger.info("Simulating DOCX output generation (Pandoc not available/used in this environment).")
        try:
            # Ensure output directory exists
            output_dir = os.path.dirname(output_md_filepath)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)

            with open(output_md_filepath, "w", encoding="utf-8") as f:
                f.write(markdown_content)

            message = (f"DOCX generation simulation: Markdown content saved to '{output_md_filepath}'.\n"
                       f"To convert to DOCX, please use a local Pandoc installation: \n"
                       f"  pandoc \"{output_md_filepath}\" -o \"{output_md_filepath.replace('.md', '.docx')}\" --reference-doc=your_style_reference.docx (optional)")
            logger.info(message)
            return {"success": True, "message": message, "markdown_filepath": output_md_filepath}
        except Exception as e:
            error_message = f"Error during DOCX simulation (saving Markdown): {e}"
            logger.error(error_message)
            return {"success": False, "message": error_message, "markdown_filepath": None}

    def to_pdf_simulation(self, latex_content: str, output_tex_filepath: str = "output/survey_draft.tex") -> dict:
        """
        Simulates PDF generation by saving the LaTeX content and providing instructions.
        Args:
            latex_content: The LaTeX string.
            output_tex_filepath: Path to save the LaTeX (.tex) file.
        Returns:
            A dictionary with a message and the path to the saved .tex file.
        """
        logger.info("Simulating PDF output generation (direct PDF compilation not available in this environment).")
        try:
            # Ensure output directory exists
            output_dir = os.path.dirname(output_tex_filepath)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)

            with open(output_tex_filepath, "w", encoding="utf-8") as f:
                f.write(latex_content)

            message = (f"PDF generation simulation: LaTeX content saved to '{output_tex_filepath}'.\n"
                       f"To convert to PDF, please use a local LaTeX distribution (e.g., TeX Live, MiKTeX) to compile the .tex file:\n"
                       f"  pdflatex \"{output_tex_filepath}\" (run twice for references/TOC)\n"
                       f"  (Or use an online LaTeX editor like Overleaf by uploading the .tex file)")
            logger.info(message)
            return {"success": True, "message": message, "latex_filepath": output_tex_filepath}
        except Exception as e:
            error_message = f"Error during PDF simulation (saving LaTeX): {e}"
            logger.error(error_message)
            return {"success": False, "message": error_message, "latex_filepath": None}


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    engine = WritingEngine()

    # Sample data from KnowledgeWeaver (using the structure from the updated KW)
    mock_kw_data = {
        "overall_topic": "AI in Medical Diagnostics: A Survey of Recent Advances",
        "introduction_text": "This report reviews recent advancements in AI for medical diagnostics, covering 15 papers. Key themes include CNNs in imaging and NLP for patient data.",
        "themed_sections": [
            {
                "theme_name": "CNN Applications in Radiology",
                "theme_summary": "Convolutional Neural Networks (CNNs) are widely used for analyzing radiological images. This theme covers 2 paper(s). Key aspects include: Paper 'CNNs for X-Ray Analysis' (arxiv:001) reports: Novel CNN architecture.; Paper 'Advanced CNNs for Medical Imaging' (arxiv:003) reports: EfficientNet variant for faster processing..",
                "papers_in_theme": ["arxiv:001", "arxiv:003"],
                "paper_titles_in_theme": ["Paper on CNNs for X-Ray Analysis", "Advanced CNNs for Medical Imaging"],
                "has_quantitative_data": True,
                "representative_keywords": ["CNN", "Deep Learning", "Image Classification"]
            },
            {
                "theme_name": "NLP for Clinical Notes",
                "theme_summary": "Natural Language Processing (NLP) techniques, particularly Transformers like BERT, are applied to extract insights from clinical notes. This theme covers 1 paper(s). Key aspects include: Paper 'NLP for Patient Record Summarization' (pubmed:002) reports: New summarization technique using BERT..",
                "papers_in_theme": ["pubmed:002"],
                "paper_titles_in_theme": ["NLP for Patient Record Summarization"],
                "has_quantitative_data": False,
                "representative_keywords": ["NLP", "Transformer", "BERT"]
            }
        ],
        "methodology_overview": [
            {"method": "CNN", "count": 2},
            {"method": "Deep Learning", "count": 2},
            {"method": "NLP", "count": 1},
            {"method": "Transformer", "count": 1},
        ],
        "reproducibility_summary_data": {
            "total_papers_checked_for_reproducibility": 2,
            "total_papers_reproduced_successfully": 1,
            "details": [
                {"paper_id": "arxiv:001", "title": "Paper on CNNs for X-Ray Analysis", "checked": True, "reproduced": True, "success_rate": 0.9, "url": "git://cnn_xray"},
                {"paper_id": "pubmed:002", "title": "NLP for Patient Record Summarization", "checked": True, "reproduced": False, "success_rate": 0.4, "url": "git://bert_summarizer"},
                 {"paper_id": "arxiv:003", "title": "Advanced CNNs for Medical Imaging", "checked": False} # Example of not checked
            ]
        },
        "conclusion_text": "AI shows great promise in medical diagnostics, with CNNs and NLP leading the way. Reproducibility and data diversity are key challenges.",
        "source_evidence_packages": [ # Abbreviated for this test
            {"paper_id": "arxiv:001", "title": "Paper on CNNs for X-Ray Analysis", "source_url": "http://arxiv.org/abs/001"},
            {"paper_id": "pubmed:002", "title": "NLP for Patient Record Summarization", "source_url": "http://pubmed.gov/002"},
            {"paper_id": "arxiv:003", "title": "Advanced CNNs for Medical Imaging", "source_url": "http://arxiv.org/abs/003"}
        ],
        "statistics": {"total_papers_analyzed": 3, "total_claims_processed": 5, "total_themes_identified": 2}
    }

    draft = engine.compose(mock_kw_data, output_format="markdown") # Explicitly markdown for this part of test
    print("\n--- Composed Draft (Markdown) ---")
    print(draft)
    print("\n--- End of Draft ---")

    print("\n--- Testing LaTeX Output ---")
    latex_draft = engine.compose(mock_kw_data, output_format="latex")
    print(latex_draft[:1000] + "\n...\n... (LaTeX output truncated) ...") # Print a snippet
    # To save:
    # with open("output/survey_draft.tex", "w", encoding="utf-8") as f:
    #     f.write(latex_draft)
    # logger.info("LaTeX draft saved to output/survey_draft.tex (example path)")
    print("\n--- End of LaTeX Output Test ---")

    # --- Test DOCX Simulation ---
    # md_content_for_docx was already generated as 'draft'
    docx_simulation_result = engine.to_docx_simulation(draft, "output/survey_draft_for_docx_conversion.md")
    logger.info(docx_simulation_result["message"])
    if docx_simulation_result.get("success") and docx_simulation_result.get("markdown_filepath"):
        # Check if the markdown file was saved by the simulation
        if os.path.exists(docx_simulation_result['markdown_filepath']):
            logger.info(f"Markdown file for DOCX conversion saved at: {docx_simulation_result['markdown_filepath']}")
    # --- End Test DOCX Simulation ---

    # --- Test PDF Simulation ---
    # latex_draft was already generated above
    pdf_simulation_result = engine.to_pdf_simulation(latex_draft, "output/survey_draft.tex")
    logger.info(pdf_simulation_result["message"])
    if pdf_simulation_result.get("success") and pdf_simulation_result.get("latex_filepath"):
        if os.path.exists(pdf_simulation_result["latex_filepath"]):
            logger.info(f"LaTeX file for PDF conversion saved at: {pdf_simulation_result['latex_filepath']}")
    # --- End Test PDF Simulation ---


    # Test visualization text output (internal detail, but can be useful)
    # if engine.template : # Check if template loaded
    #     viz_text_meth = engine._generate_text_visualization(
    #         data=mock_kw_data["methodology_overview"],
    #         title="Methodology Test", value_key="count", label_key="method"
    #     )
    #     print("\n--- Sample Text Visualization (Methodologies) ---")
    #     print(viz_text_meth["text_content"])

    #     repro_chart_data = [
    #         {"status": "Reproduced", "count": mock_kw_data["reproducibility_summary_data"]["total_papers_reproduced_successfully"]},
    #         {"status": "Not Reproduced", "count": mock_kw_data["reproducibility_summary_data"]["total_papers_checked_for_reproducibility"] - mock_kw_data["reproducibility_summary_data"]["total_papers_reproduced_successfully"]}
    #     ]
    #     viz_text_repro = engine._generate_text_visualization(
    #         data=repro_chart_data,
    #         title="Reproducibility Test", value_key="count", label_key="status"
    #     )
    #     print("\n--- Sample Text Visualization (Reproducibility) ---")
    #     print(viz_text_repro["text_content"])
